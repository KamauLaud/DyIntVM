{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code  \n",
    "---\n",
    "This code is taken from: https://github.com/rafikg/CEAL\n",
    "## Import all the required stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported from run_ceal/ceal_learning_algorithm.py\n",
    "from model import AlexNet\n",
    "from utils import Normalize, RandomCrop, SquarifyImage, \\\n",
    "    ToTensor, GameImageDataset\n",
    "from utils import get_uncertain_samples, get_high_confidence_samples, \\\n",
    "    update_threshold\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "\n",
    "# others\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s:%(name)s: %(message)s\",\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEAL Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceal_learning_algorithm(du: DataLoader,\n",
    "                            dl: DataLoader,\n",
    "                            dtest: DataLoader,\n",
    "                            k: int = 5,\n",
    "                            delta_0: float = 0.005,\n",
    "                            dr: float = 0.00033,\n",
    "                            t: int = 1,\n",
    "                            epochs: int = 10,\n",
    "                            criteria: str = 'cl',\n",
    "                            max_iter: int = 10):\n",
    "    \"\"\"\n",
    "    Algorithm1 : Learning algorithm of CEAL.\n",
    "    For simplicity, I used the same notation in the paper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    du: DataLoader\n",
    "        Unlabeled samples\n",
    "    dl : DataLoader\n",
    "        labeled samples\n",
    "    dtest : DataLoader\n",
    "        test data\n",
    "    k: int, (default = 1000)\n",
    "        uncertain samples selection\n",
    "    delta_0: float\n",
    "        hight confidence samples selection threshold\n",
    "    dr: float\n",
    "        threshold decay\n",
    "    t: int\n",
    "        fine-tuning interval\n",
    "    epochs: int\n",
    "    criteria: str\n",
    "    max_iter: int\n",
    "        maximum iteration number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    logger.info('Initial configuration: len(du): {}, len(dl): {} '.format(\n",
    "        len(du.sampler.indices),\n",
    "        len(dl.sampler.indices)))\n",
    "\n",
    "    # Create the model\n",
    "    model = AlexNet(n_classes=4, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    logger.info('Intialize training the model on `dl` and test on `dtest`')\n",
    "\n",
    "    model.train(epochs=epochs, train_loader=dl, valid_loader=None)\n",
    "\n",
    "    # Evaluate model on dtest\n",
    "    p, r, f = model.evaluate(test_loader=dtest)\n",
    "\n",
    "    print('====> Initial precision: {} '.format(p))\n",
    "    print('====> Initial recall: {} '.format(r))\n",
    "    print('====> Initial f-score: {} '.format(f))\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "\n",
    "        logger.info('Iteration: {}: run prediction on unlabeled data '\n",
    "                    '`du` '.format(iteration))\n",
    "\n",
    "        pred_prob = model.predict(test_loader=du)\n",
    "\n",
    "        # get k uncertain samples\n",
    "        uncert_samp_idx, _ = get_uncertain_samples(pred_prob=pred_prob, k=k,\n",
    "                                                   criteria=criteria)\n",
    "\n",
    "        # get original indices\n",
    "        uncert_samp_idx = [du.sampler.indices[idx] for idx in uncert_samp_idx]\n",
    "\n",
    "        # add the uncertain samples selected from `du` to the labeled samples\n",
    "        #  set `dl`\n",
    "        dl.sampler.indices.extend(uncert_samp_idx)\n",
    "\n",
    "        logger.info(\n",
    "            'Update size of `dl`  and `du` by adding uncertain {} samples'\n",
    "            ' in `dl`'\n",
    "            ' len(dl): {}, len(du) {}'.\n",
    "            format(len(uncert_samp_idx), len(dl.sampler.indices),\n",
    "                   len(du.sampler.indices)))\n",
    "\n",
    "        # get high confidence samples `dh`\n",
    "        hcs_idx, hcs_labels = get_high_confidence_samples(pred_prob=pred_prob,\n",
    "                                                          delta=delta_0)\n",
    "        # get the original indices\n",
    "        hcs_idx = [du.sampler.indices[idx] for idx in hcs_idx]\n",
    "\n",
    "        # remove the samples that already selected as uncertain samples.\n",
    "        hcs_idx = [x for x in hcs_idx if\n",
    "                   x not in list(set(uncert_samp_idx) & set(hcs_idx))]\n",
    "\n",
    "        # add high confidence samples to the labeled set 'dl'\n",
    "\n",
    "        # (1) update the indices\n",
    "        dl.sampler.indices.extend(hcs_idx)\n",
    "        # (2) update the original labels with the pseudo labels.\n",
    "        for idx in range(len(hcs_idx)):\n",
    "            dl.dataset.labels[hcs_idx[idx]] = hcs_labels[idx]\n",
    "        logger.info(\n",
    "            'Update size of `dl`  and `du` by adding {} hcs samples in `dl`'\n",
    "            ' len(dl): {}, len(du) {}'.\n",
    "            format(len(hcs_idx), len(dl.sampler.indices),\n",
    "                   len(du.sampler.indices)))\n",
    "\n",
    "        if iteration % t == 0:\n",
    "            logger.info('Iteration: {} fine-tune the model on dh U dl'.\n",
    "                        format(iteration))\n",
    "            model.train(epochs=epochs, train_loader=dl)\n",
    "\n",
    "            # update delta_0\n",
    "            delta_0 = update_threshold(delta=delta_0, dr=dr, t=iteration)\n",
    "\n",
    "        # remove the uncertain samples from the original `du`\n",
    "        logger.info('remove {} uncertain samples from du'.\n",
    "                    format(len(uncert_samp_idx)))\n",
    "        for val in uncert_samp_idx:\n",
    "            du.sampler.indices.remove(val)\n",
    "\n",
    "        p, r, f = model.evaluate(test_loader=dtest)\n",
    "        print(\n",
    "            \"Iteration: {}, len(dl): {}, len(du): {},\"\n",
    "            \" len(dh) {}, p: {} r: {} f: {} \".format(\n",
    "                iteration, len(dl.sampler.indices),\n",
    "                len(du.sampler.indices), len(hcs_idx), p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Initial configuration: len(du): 54, len(dl): 5 \n",
      "INFO:model.alexnet: The code is running on cuda:0 \n",
      "INFO:__main__: Intialize training the model on `dl` and test on `dtest`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/5 (0%)]\tLoss: 0.836975\n",
      "====> Epoch: 0 Average loss: 0.1674\n",
      "Train Epoch: 1 [0/5 (0%)]\tLoss: 0.744073\n",
      "====> Epoch: 1 Average loss: 0.1488\n",
      "Train Epoch: 2 [0/5 (0%)]\tLoss: 0.666604\n",
      "====> Epoch: 2 Average loss: 0.1333\n",
      "Train Epoch: 3 [0/5 (0%)]\tLoss: 0.469242\n",
      "====> Epoch: 3 Average loss: 0.0938\n",
      "Train Epoch: 4 [0/5 (0%)]\tLoss: 0.428043\n",
      "====> Epoch: 4 Average loss: 0.0856\n",
      "Train Epoch: 5 [0/5 (0%)]\tLoss: 0.337586\n",
      "====> Epoch: 5 Average loss: 0.0675\n",
      "Train Epoch: 6 [0/5 (0%)]\tLoss: 0.239283\n",
      "====> Epoch: 6 Average loss: 0.0479\n",
      "Train Epoch: 7 [0/5 (0%)]\tLoss: 0.226031\n",
      "====> Epoch: 7 Average loss: 0.0452\n",
      "Train Epoch: 8 [0/5 (0%)]\tLoss: 0.171328\n",
      "====> Epoch: 8 Average loss: 0.0343\n",
      "Train Epoch: 9 [0/5 (0%)]\tLoss: 0.119094\n",
      "====> Epoch: 9 Average loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 0: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Initial precision: [0.4, 0.5454545454545454, 0.0, 0.0] \n",
      "====> Initial recall: [1.0, 0.75, 0.0, 0.0] \n",
      "====> Initial f-score: [0.5714285714285715, 0.631578947368421, 0.0, 0.0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 10, len(du) 54\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 10, len(du) 54\n",
      "INFO:__main__: Iteration: 0 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/10 (0%)]\tLoss: 0.511677\n",
      "====> Epoch: 0 Average loss: 0.0512\n",
      "Train Epoch: 1 [0/10 (0%)]\tLoss: 0.432363\n",
      "====> Epoch: 1 Average loss: 0.0432\n",
      "Train Epoch: 2 [0/10 (0%)]\tLoss: 0.381932\n",
      "====> Epoch: 2 Average loss: 0.0382\n",
      "Train Epoch: 3 [0/10 (0%)]\tLoss: 0.291052\n",
      "====> Epoch: 3 Average loss: 0.0291\n",
      "Train Epoch: 4 [0/10 (0%)]\tLoss: 0.202707\n",
      "====> Epoch: 4 Average loss: 0.0203\n",
      "Train Epoch: 5 [0/10 (0%)]\tLoss: 0.197379\n",
      "====> Epoch: 5 Average loss: 0.0197\n",
      "Train Epoch: 6 [0/10 (0%)]\tLoss: 0.255438\n",
      "====> Epoch: 6 Average loss: 0.0255\n",
      "Train Epoch: 7 [0/10 (0%)]\tLoss: 0.262764\n",
      "====> Epoch: 7 Average loss: 0.0263\n",
      "Train Epoch: 8 [0/10 (0%)]\tLoss: 0.246797\n",
      "====> Epoch: 8 Average loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/10 (0%)]\tLoss: 0.214122\n",
      "====> Epoch: 9 Average loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 1: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, len(dl): 10, len(du): 49, len(dh) 0, p: [0.75, 0.5, 0.0, 0.25] r: [0.5, 0.375, 0.0, 0.14285714285714285] f: [0.6, 0.42857142857142855, 0.0, 0.18181818181818182] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 15, len(du) 49\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 15, len(du) 49\n",
      "INFO:__main__: Iteration: 1 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/15 (0%)]\tLoss: 0.383865\n",
      "====> Epoch: 0 Average loss: 0.0256\n",
      "Train Epoch: 1 [0/15 (0%)]\tLoss: 0.346162\n",
      "====> Epoch: 1 Average loss: 0.0231\n",
      "Train Epoch: 2 [0/15 (0%)]\tLoss: 0.318733\n",
      "====> Epoch: 2 Average loss: 0.0212\n",
      "Train Epoch: 3 [0/15 (0%)]\tLoss: 0.310839\n",
      "====> Epoch: 3 Average loss: 0.0207\n",
      "Train Epoch: 4 [0/15 (0%)]\tLoss: 0.358089\n",
      "====> Epoch: 4 Average loss: 0.0239\n",
      "Train Epoch: 5 [0/15 (0%)]\tLoss: 0.309989\n",
      "====> Epoch: 5 Average loss: 0.0207\n",
      "Train Epoch: 6 [0/15 (0%)]\tLoss: 0.259233\n",
      "====> Epoch: 6 Average loss: 0.0173\n",
      "Train Epoch: 7 [0/15 (0%)]\tLoss: 0.212229\n",
      "====> Epoch: 7 Average loss: 0.0141\n",
      "Train Epoch: 8 [0/15 (0%)]\tLoss: 0.220555\n",
      "====> Epoch: 8 Average loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/15 (0%)]\tLoss: 0.217818\n",
      "====> Epoch: 9 Average loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 2: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, len(dl): 15, len(du): 44, len(dh) 0, p: [0.5555555555555556, 0.5, 0.0, 0.5] r: [0.8333333333333334, 0.25, 0.0, 0.2857142857142857] f: [0.6666666666666667, 0.3333333333333333, 0.0, 0.36363636363636365] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 20, len(du) 44\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 20, len(du) 44\n",
      "INFO:__main__: Iteration: 2 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/20 (0%)]\tLoss: 0.417710\n",
      "====> Epoch: 0 Average loss: 0.0286\n",
      "Train Epoch: 1 [0/20 (0%)]\tLoss: 0.289904\n",
      "====> Epoch: 1 Average loss: 0.0423\n",
      "Train Epoch: 2 [0/20 (0%)]\tLoss: 0.317044\n",
      "====> Epoch: 2 Average loss: 0.0262\n",
      "Train Epoch: 3 [0/20 (0%)]\tLoss: 0.234210\n",
      "====> Epoch: 3 Average loss: 0.0260\n",
      "Train Epoch: 4 [0/20 (0%)]\tLoss: 0.281800\n",
      "====> Epoch: 4 Average loss: 0.0290\n",
      "Train Epoch: 5 [0/20 (0%)]\tLoss: 0.260994\n",
      "====> Epoch: 5 Average loss: 0.0201\n",
      "Train Epoch: 6 [0/20 (0%)]\tLoss: 0.192407\n",
      "====> Epoch: 6 Average loss: 0.0227\n",
      "Train Epoch: 7 [0/20 (0%)]\tLoss: 0.223880\n",
      "====> Epoch: 7 Average loss: 0.0274\n",
      "Train Epoch: 8 [0/20 (0%)]\tLoss: 0.184139\n",
      "====> Epoch: 8 Average loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/20 (0%)]\tLoss: 0.197886\n",
      "====> Epoch: 9 Average loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 3: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, len(dl): 20, len(du): 39, len(dh) 0, p: [0.8333333333333334, 0.3333333333333333, 1.0, 1.0] r: [0.8333333333333334, 0.25, 0.4, 0.14285714285714285] f: [0.8333333333333334, 0.28571428571428575, 0.5714285714285715, 0.25] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 25, len(du) 39\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 25, len(du) 39\n",
      "INFO:__main__: Iteration: 3 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/25 (0%)]\tLoss: 0.378549\n",
      "====> Epoch: 0 Average loss: 0.0295\n",
      "Train Epoch: 1 [0/25 (0%)]\tLoss: 0.484704\n",
      "====> Epoch: 1 Average loss: 0.0289\n",
      "Train Epoch: 2 [0/25 (0%)]\tLoss: 0.275374\n",
      "====> Epoch: 2 Average loss: 0.0279\n",
      "Train Epoch: 3 [0/25 (0%)]\tLoss: 0.312932\n",
      "====> Epoch: 3 Average loss: 0.0232\n",
      "Train Epoch: 4 [0/25 (0%)]\tLoss: 0.313706\n",
      "====> Epoch: 4 Average loss: 0.0240\n",
      "Train Epoch: 5 [0/25 (0%)]\tLoss: 0.299783\n",
      "====> Epoch: 5 Average loss: 0.0220\n",
      "Train Epoch: 6 [0/25 (0%)]\tLoss: 0.249631\n",
      "====> Epoch: 6 Average loss: 0.0200\n",
      "Train Epoch: 7 [0/25 (0%)]\tLoss: 0.247325\n",
      "====> Epoch: 7 Average loss: 0.0195\n",
      "Train Epoch: 8 [0/25 (0%)]\tLoss: 0.264662\n",
      "====> Epoch: 8 Average loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/25 (0%)]\tLoss: 0.196698\n",
      "====> Epoch: 9 Average loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 4: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3, len(dl): 25, len(du): 34, len(dh) 0, p: [0.42857142857142855, 0.5, 0.6666666666666666, 0.0] r: [0.5, 0.25, 0.4, 0.0] f: [0.4615384615384615, 0.3333333333333333, 0.5, 0.0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 30, len(du) 34\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 30, len(du) 34\n",
      "INFO:__main__: Iteration: 4 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/30 (0%)]\tLoss: 0.221590\n",
      "====> Epoch: 0 Average loss: 0.0166\n",
      "Train Epoch: 1 [0/30 (0%)]\tLoss: 0.197600\n",
      "====> Epoch: 1 Average loss: 0.0158\n",
      "Train Epoch: 2 [0/30 (0%)]\tLoss: 0.249994\n",
      "====> Epoch: 2 Average loss: 0.0163\n",
      "Train Epoch: 3 [0/30 (0%)]\tLoss: 0.325779\n",
      "====> Epoch: 3 Average loss: 0.0158\n",
      "Train Epoch: 4 [0/30 (0%)]\tLoss: 0.185305\n",
      "====> Epoch: 4 Average loss: 0.0143\n",
      "Train Epoch: 5 [0/30 (0%)]\tLoss: 0.195734\n",
      "====> Epoch: 5 Average loss: 0.0155\n",
      "Train Epoch: 6 [0/30 (0%)]\tLoss: 0.225513\n",
      "====> Epoch: 6 Average loss: 0.0156\n",
      "Train Epoch: 7 [0/30 (0%)]\tLoss: 0.211771\n",
      "====> Epoch: 7 Average loss: 0.0127\n",
      "Train Epoch: 8 [0/30 (0%)]\tLoss: 0.142174\n",
      "====> Epoch: 8 Average loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/30 (0%)]\tLoss: 0.189507\n",
      "====> Epoch: 9 Average loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 5: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4, len(dl): 30, len(du): 29, len(dh) 0, p: [0.6666666666666666, 0.4, 1.0, 0.5] r: [0.6666666666666666, 0.25, 0.6, 0.42857142857142855] f: [0.6666666666666666, 0.3076923076923077, 0.7499999999999999, 0.4615384615384615] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 35, len(du) 29\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 35, len(du) 29\n",
      "INFO:__main__: Iteration: 5 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/35 (0%)]\tLoss: 0.222596\n",
      "====> Epoch: 0 Average loss: 0.0175\n",
      "Train Epoch: 1 [0/35 (0%)]\tLoss: 0.181133\n",
      "====> Epoch: 1 Average loss: 0.0156\n",
      "Train Epoch: 2 [0/35 (0%)]\tLoss: 0.238723\n",
      "====> Epoch: 2 Average loss: 0.0165\n",
      "Train Epoch: 3 [0/35 (0%)]\tLoss: 0.198460\n",
      "====> Epoch: 3 Average loss: 0.0142\n",
      "Train Epoch: 4 [0/35 (0%)]\tLoss: 0.171864\n",
      "====> Epoch: 4 Average loss: 0.0179\n",
      "Train Epoch: 5 [0/35 (0%)]\tLoss: 0.200227\n",
      "====> Epoch: 5 Average loss: 0.0158\n",
      "Train Epoch: 6 [0/35 (0%)]\tLoss: 0.169854\n",
      "====> Epoch: 6 Average loss: 0.0133\n",
      "Train Epoch: 7 [0/35 (0%)]\tLoss: 0.183964\n",
      "====> Epoch: 7 Average loss: 0.0145\n",
      "Train Epoch: 8 [0/35 (0%)]\tLoss: 0.172132\n",
      "====> Epoch: 8 Average loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/35 (0%)]\tLoss: 0.213040\n",
      "====> Epoch: 9 Average loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 6: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5, len(dl): 35, len(du): 24, len(dh) 0, p: [0.5714285714285714, 0.0, 1.0, 0.5] r: [0.6666666666666666, 0.0, 0.6, 0.42857142857142855] f: [0.6153846153846153, 0.0, 0.7499999999999999, 0.4615384615384615] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 40, len(du) 24\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 40, len(du) 24\n",
      "INFO:__main__: Iteration: 6 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/40 (0%)]\tLoss: 0.322165\n",
      "====> Epoch: 0 Average loss: 0.0157\n",
      "Train Epoch: 1 [0/40 (0%)]\tLoss: 0.121313\n",
      "====> Epoch: 1 Average loss: 0.0146\n",
      "Train Epoch: 2 [0/40 (0%)]\tLoss: 0.252793\n",
      "====> Epoch: 2 Average loss: 0.0140\n",
      "Train Epoch: 3 [0/40 (0%)]\tLoss: 0.208742\n",
      "====> Epoch: 3 Average loss: 0.0180\n",
      "Train Epoch: 4 [0/40 (0%)]\tLoss: 0.191178\n",
      "====> Epoch: 4 Average loss: 0.0153\n",
      "Train Epoch: 5 [0/40 (0%)]\tLoss: 0.153049\n",
      "====> Epoch: 5 Average loss: 0.0104\n",
      "Train Epoch: 6 [0/40 (0%)]\tLoss: 0.149012\n",
      "====> Epoch: 6 Average loss: 0.0108\n",
      "Train Epoch: 7 [0/40 (0%)]\tLoss: 0.152559\n",
      "====> Epoch: 7 Average loss: 0.0108\n",
      "Train Epoch: 8 [0/40 (0%)]\tLoss: 0.145430\n",
      "====> Epoch: 8 Average loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/40 (0%)]\tLoss: 0.159814\n",
      "====> Epoch: 9 Average loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 7: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6, len(dl): 40, len(du): 19, len(dh) 0, p: [0.625, 0.2, 1.0, 0.4] r: [0.8333333333333334, 0.125, 0.4, 0.2857142857142857] f: [0.7142857142857143, 0.15384615384615385, 0.5714285714285715, 0.3333333333333333] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 45, len(du) 19\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 45, len(du) 19\n",
      "INFO:__main__: Iteration: 7 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/45 (0%)]\tLoss: 0.178656\n",
      "====> Epoch: 0 Average loss: 0.0140\n",
      "Train Epoch: 1 [0/45 (0%)]\tLoss: 0.302028\n",
      "====> Epoch: 1 Average loss: 0.0147\n",
      "Train Epoch: 2 [0/45 (0%)]\tLoss: 0.203362\n",
      "====> Epoch: 2 Average loss: 0.0155\n",
      "Train Epoch: 3 [0/45 (0%)]\tLoss: 0.223826\n",
      "====> Epoch: 3 Average loss: 0.0125\n",
      "Train Epoch: 4 [0/45 (0%)]\tLoss: 0.147627\n",
      "====> Epoch: 4 Average loss: 0.0116\n",
      "Train Epoch: 5 [0/45 (0%)]\tLoss: 0.292854\n",
      "====> Epoch: 5 Average loss: 0.0126\n",
      "Train Epoch: 6 [0/45 (0%)]\tLoss: 0.200696\n",
      "====> Epoch: 6 Average loss: 0.0127\n",
      "Train Epoch: 7 [0/45 (0%)]\tLoss: 0.167931\n",
      "====> Epoch: 7 Average loss: 0.0116\n",
      "Train Epoch: 8 [0/45 (0%)]\tLoss: 0.203681\n",
      "====> Epoch: 8 Average loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/45 (0%)]\tLoss: 0.214393\n",
      "====> Epoch: 9 Average loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 8: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7, len(dl): 45, len(du): 14, len(dh) 0, p: [0.5555555555555556, 0.75, 1.0, 0.5] r: [0.8333333333333334, 0.375, 0.4, 0.2857142857142857] f: [0.6666666666666667, 0.5, 0.5714285714285715, 0.36363636363636365] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 50, len(du) 14\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 50, len(du) 14\n",
      "INFO:__main__: Iteration: 8 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 0.411815\n",
      "====> Epoch: 0 Average loss: 0.0172\n",
      "Train Epoch: 1 [0/50 (0%)]\tLoss: 0.215062\n",
      "====> Epoch: 1 Average loss: 0.0168\n",
      "Train Epoch: 2 [0/50 (0%)]\tLoss: 0.201627\n",
      "====> Epoch: 2 Average loss: 0.0173\n",
      "Train Epoch: 3 [0/50 (0%)]\tLoss: 0.144989\n",
      "====> Epoch: 3 Average loss: 0.0172\n",
      "Train Epoch: 4 [0/50 (0%)]\tLoss: 0.232741\n",
      "====> Epoch: 4 Average loss: 0.0161\n",
      "Train Epoch: 5 [0/50 (0%)]\tLoss: 0.253391\n",
      "====> Epoch: 5 Average loss: 0.0125\n",
      "Train Epoch: 6 [0/50 (0%)]\tLoss: 0.223070\n",
      "====> Epoch: 6 Average loss: 0.0136\n",
      "Train Epoch: 7 [0/50 (0%)]\tLoss: 0.190642\n",
      "====> Epoch: 7 Average loss: 0.0131\n",
      "Train Epoch: 8 [0/50 (0%)]\tLoss: 0.136055\n",
      "====> Epoch: 8 Average loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/50 (0%)]\tLoss: 0.198687\n",
      "====> Epoch: 9 Average loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Iteration: 9: run prediction on unlabeled data `du` \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8, len(dl): 50, len(du): 9, len(dh) 0, p: [0.5555555555555556, 0.4, 0.75, 0.6] r: [0.8333333333333334, 0.25, 0.6, 0.42857142857142855] f: [0.6666666666666667, 0.3076923076923077, 0.6666666666666665, 0.5] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: Update size of `dl`  and `du` by adding uncertain 5 samples in `dl` len(dl): 55, len(du) 9\n",
      "INFO:__main__: Update size of `dl`  and `du` by adding 0 hcs samples in `dl` len(dl): 55, len(du) 9\n",
      "INFO:__main__: Iteration: 9 fine-tune the model on dh U dl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/55 (0%)]\tLoss: 0.162597\n",
      "====> Epoch: 0 Average loss: 0.0145\n",
      "Train Epoch: 1 [0/55 (0%)]\tLoss: 0.243147\n",
      "====> Epoch: 1 Average loss: 0.0140\n",
      "Train Epoch: 2 [0/55 (0%)]\tLoss: 0.281640\n",
      "====> Epoch: 2 Average loss: 0.0137\n",
      "Train Epoch: 3 [0/55 (0%)]\tLoss: 0.112853\n",
      "====> Epoch: 3 Average loss: 0.0153\n",
      "Train Epoch: 4 [0/55 (0%)]\tLoss: 0.260125\n",
      "====> Epoch: 4 Average loss: 0.0146\n",
      "Train Epoch: 5 [0/55 (0%)]\tLoss: 0.145331\n",
      "====> Epoch: 5 Average loss: 0.0145\n",
      "Train Epoch: 6 [0/55 (0%)]\tLoss: 0.195874\n",
      "====> Epoch: 6 Average loss: 0.0164\n",
      "Train Epoch: 7 [0/55 (0%)]\tLoss: 0.160361\n",
      "====> Epoch: 7 Average loss: 0.0122\n",
      "Train Epoch: 8 [0/55 (0%)]\tLoss: 0.146012\n",
      "====> Epoch: 8 Average loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__: remove 5 uncertain samples from du\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/55 (0%)]\tLoss: 0.238593\n",
      "====> Epoch: 9 Average loss: 0.0154\n",
      "Iteration: 9, len(dl): 55, len(du): 4, len(dh) 0, p: [0.5555555555555556, 0.6, 0.6666666666666666, 0.4] r: [0.8333333333333334, 0.375, 0.4, 0.2857142857142857] f: [0.6666666666666667, 0.4615384615384615, 0.5, 0.3333333333333333] \n"
     ]
    }
   ],
   "source": [
    "dataset_train = GameImageDataset(\n",
    "    root_dir=\"data/train\",\n",
    "    transform=transforms.Compose(\n",
    "        [SquarifyImage(),\n",
    "         RandomCrop(224),\n",
    "         Normalize(),\n",
    "         ToTensor()]))\n",
    "\n",
    "dataset_test = GameImageDataset(\n",
    "    root_dir=\"data/test\",\n",
    "    transform=transforms.Compose(\n",
    "        [SquarifyImage(),\n",
    "         RandomCrop(224),\n",
    "         Normalize(),\n",
    "         ToTensor()]))\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "random_seed = 123\n",
    "validation_split = 0.1  # 10%\n",
    "shuffling_dataset = True\n",
    "batch_size = 16\n",
    "dataset_size = len(dataset_train)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffling_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "du = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
    "                                 sampler=train_sampler, num_workers=4)\n",
    "dl = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
    "                                 sampler=valid_sampler, num_workers=4)\n",
    "dtest = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size,\n",
    "                                    num_workers=4)\n",
    "\n",
    "ceal_learning_algorithm(du=du, dl=dl, dtest=dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra processing\n",
    "---\n",
    "The cells are converted to markdown cells so that they are not run when you run all cells. Change them to code cells to run if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting data zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('annotated-20210501T142205Z-001.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move files to train and test directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "dataitems = os.listdir('data')\n",
    "finalitems = []\n",
    "for item in dataitems:\n",
    "    if not os.path.isdir('data/'+item):\n",
    "        finalitems.append(item)\n",
    "\n",
    "for idx, item in enumerate(finalitems):\n",
    "    # this will assign 20% images(every 5th image) to the test directory\n",
    "    if idx % 5 == 0: \n",
    "        os.rename('data/' + item, 'data/test/'+item)\n",
    "    else:\n",
    "        os.rename('data/' + item, 'data/train/'+item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
